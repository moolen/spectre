"use strict";(globalThis.webpackChunkspectre_docs=globalThis.webpackChunkspectre_docs||[]).push([[8488],{2534:(e,n,i)=>{i.r(n),i.d(n,{assets:()=>a,contentTitle:()=>l,default:()=>p,frontMatter:()=>o,metadata:()=>s,toc:()=>c});const s=JSON.parse('{"id":"mcp-integration/examples","title":"MCP Real-World Examples","description":"Complete investigation scenarios demonstrating Spectre MCP capabilities","source":"@site/docs/mcp-integration/examples.md","sourceDirName":"mcp-integration","slug":"/mcp-integration/examples","permalink":"/spectre/docs/mcp-integration/examples","draft":false,"unlisted":false,"editUrl":"https://github.com/moolen/spectre/tree/master/docs/docs/mcp-integration/examples.md","tags":[],"version":"current","lastUpdatedBy":"Moritz Johner","lastUpdatedAt":1765616329000,"frontMatter":{"title":"MCP Real-World Examples","description":"Complete investigation scenarios demonstrating Spectre MCP capabilities","keywords":["examples","mcp","claude","scenarios","investigations","troubleshooting","post-mortem"]},"sidebar":"docsSidebar","previous":{"title":"Claude Desktop Integration","permalink":"/spectre/docs/mcp-integration/claude-integration"},"next":{"title":"Architecture","permalink":"/spectre/docs/architecture/"}}');var r=i(4848),t=i(8453);const o={title:"MCP Real-World Examples",description:"Complete investigation scenarios demonstrating Spectre MCP capabilities",keywords:["examples","mcp","claude","scenarios","investigations","troubleshooting","post-mortem"]},l="MCP Real-World Examples",a={},c=[{value:"Overview",id:"overview",level:2},{value:"Example 1: CrashLoopBackOff Investigation",id:"example-1-crashloopbackoff-investigation",level:2},{value:"Via Claude Desktop",id:"via-claude-desktop",level:3},{value:"Via HTTP API (Programmatic)",id:"via-http-api-programmatic",level:3},{value:"Example 2: Post-Mortem Analysis (Complete Workflow)",id:"example-2-post-mortem-analysis-complete-workflow",level:2},{value:"Via Claude Desktop",id:"via-claude-desktop-1",level:3},{value:"Via HTTP API",id:"via-http-api",level:3},{value:"Example 3: Live Incident Handling",id:"example-3-live-incident-handling",level:2},{value:"Via Claude Desktop",id:"via-claude-desktop-2",level:3},{value:"Recommended Action",id:"recommended-action",level:3},{value:"Monitoring for Recovery",id:"monitoring-for-recovery",level:3},{value:"Follow-Up Actions (After Recovery)",id:"follow-up-actions-after-recovery",level:3},{value:"Additional Investigation Needed",id:"additional-investigation-needed",level:3},{value:"Changes with Impact Score &gt; 0.5",id:"changes-with-impact-score--05",level:3},{value:"Changes with Impact Score 0.3-0.5",id:"changes-with-impact-score-03-05",level:3},{value:"Correlation Analysis",id:"correlation-analysis",level:3},{value:"Overall Summary",id:"overall-summary",level:3},{value:"Issues by Namespace",id:"issues-by-namespace",level:3},{value:"Top Priority Issues",id:"top-priority-issues",level:3}];function d(e){const n={a:"a",br:"br",code:"code",h1:"h1",h2:"h2",h3:"h3",header:"header",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,t.R)(),...e.components};return(0,r.jsxs)(r.Fragment,{children:[(0,r.jsx)(n.header,{children:(0,r.jsx)(n.h1,{id:"mcp-real-world-examples",children:"MCP Real-World Examples"})}),"\n",(0,r.jsx)(n.p,{children:"Practical scenarios demonstrating how to use Spectre's MCP integration for Kubernetes troubleshooting, incident investigation, and post-mortem analysis."}),"\n",(0,r.jsx)(n.h2,{id:"overview",children:"Overview"}),"\n",(0,r.jsxs)(n.p,{children:["This guide presents ",(0,r.jsx)(n.strong,{children:"complete, end-to-end examples"})," showing:"]}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Claude Desktop conversations (natural language)"}),"\n",(0,r.jsx)(n.li,{children:"Direct HTTP API calls (programmatic access)"}),"\n",(0,r.jsx)(n.li,{children:"Expected tool outputs"}),"\n",(0,r.jsx)(n.li,{children:"How to interpret results and take action"}),"\n"]}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Scenarios covered"}),":"]}),"\n",(0,r.jsxs)(n.ol,{children:["\n",(0,r.jsx)(n.li,{children:"CrashLoopBackOff Investigation"}),"\n",(0,r.jsx)(n.li,{children:"Post-Mortem Analysis (Complete Workflow)"}),"\n",(0,r.jsx)(n.li,{children:"Live Incident Handling"}),"\n",(0,r.jsx)(n.li,{children:"Resource Change Correlation"}),"\n",(0,r.jsx)(n.li,{children:"Multi-Namespace Investigation"}),"\n",(0,r.jsx)(n.li,{children:"Custom Resource Investigation (Flux GitRepository)"}),"\n"]}),"\n",(0,r.jsx)(n.h2,{id:"example-1-crashloopbackoff-investigation",children:"Example 1: CrashLoopBackOff Investigation"}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Scenario"}),": You receive an alert that pods are failing in the production namespace. You don't know which pods or why."]}),"\n",(0,r.jsx)(n.h3,{id:"via-claude-desktop",children:"Via Claude Desktop"}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"You"}),":"]}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{children:"I got an alert about pods failing in production. Can you investigate?\n"})}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Claude"})," (Step 1 - Discovery):"]}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{children:'[Automatically calling cluster_health tool]\n\nI found issues in your production namespace. Let me investigate...\n\nCluster Health Status: Warning\n\nResources in Production Namespace:\n- Pods: 8 total (5 healthy, 3 error)\n- Deployments: 3 total (2 healthy, 1 warning)\n- Services: 4 total (all healthy)\n\nTop Issues:\n1. Pod "api-server-85f6c9b8-k4x2p" - Error (CrashLoopBackOff)\n2. Pod "api-server-85f6c9b8-m9n4r" - Error (CrashLoopBackOff)\n3. Pod "api-server-85f6c9b8-p2q7t" - Error (CrashLoopBackOff)\n\nAll three pods belong to Deployment "api-server". Would you like me to investigate\nthe deployment timeline to see what changed?\n'})}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"You"}),":"]}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{children:"Yes, investigate the deployment\n"})}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Claude"})," (Step 2 - Investigation):"]}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{children:'[Calling investigate tool for Deployment/production/api-server]\n\nTimeline for api-server Deployment:\n\n[10:05:12] Status: Ready \u2192 Warning\n           Image updated: registry.example.com/api-server:v1.2.0 \u2192 v1.3.0\n\n[10:05:45] New pods failed to start\n           Event: "Back-off restarting failed container"\n\n[10:06:30] Status: Warning (ReplicaFailure)\n           Event: "Failed to pull image registry.example.com/api-server:v1.3.0:\n                   authentication required"\n\nRoot Cause Analysis:\nThe deployment updated to image v1.3.0, but pods cannot pull the image due\nto authentication failure. This is likely an imagePullSecrets issue.\n\nImmediate Actions:\n1. Verify imagePullSecrets are configured:\n   kubectl get deployment api-server -n production -o yaml | grep imagePullSecrets\n\n2. Check if secret exists:\n   kubectl get secret regcred -n production\n\n3. Rollback deployment:\n   kubectl rollout undo deployment/api-server -n production\n\n4. Check image exists in registry:\n   docker pull registry.example.com/api-server:v1.3.0\n'})}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"You"}),":"]}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{children:"[Runs kubectl commands, confirms secret is missing]\n[Creates secret and redeploys]\nThanks! That solved it.\n"})}),"\n",(0,r.jsx)(n.h3,{id:"via-http-api-programmatic",children:"Via HTTP API (Programmatic)"}),"\n",(0,r.jsx)(n.p,{children:"Same investigation without Claude:"}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Step 1: Cluster Health Check"})}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-bash",children:'curl -X POST http://localhost:8081/mcp/v1 \\\n  -H "Content-Type: application/json" \\\n  -d "{\n    \\"jsonrpc\\": \\"2.0\\",\n    \\"method\\": \\"tools/call\\",\n    \\"params\\": {\n      \\"name\\": \\"cluster_health\\",\n      \\"arguments\\": {\n        \\"start_time\\": $(date -d \'1 hour ago\' +%s),\n        \\"end_time\\": $(date +%s),\n        \\"namespace\\": \\"production\\"\n      }\n    },\n    \\"id\\": 1\n  }"\n'})}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Response"})," (abbreviated):"]}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-json",children:'{\n  "jsonrpc": "2.0",\n  "result": {\n    "content": [{\n      "type": "text",\n      "text": "{\\"overall_status\\":\\"Warning\\",\\"resources_by_kind\\":[{\\"kind\\":\\"Pod\\",\\"total\\":8,\\"healthy\\":5,\\"error\\":3}],\\"top_issues\\":[{\\"kind\\":\\"Pod\\",\\"name\\":\\"api-server-85f6c9b8-k4x2p\\",\\"namespace\\":\\"production\\",\\"status\\":\\"Error\\",\\"message\\":\\"CrashLoopBackOff\\"}]}"\n    }]\n  },\n  "id": 1\n}\n'})}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Step 2: Investigate Deployment"})}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-bash",children:'curl -X POST http://localhost:8081/mcp/v1 \\\n  -H "Content-Type: application/json" \\\n  -d "{\n    \\"jsonrpc\\": \\"2.0\\",\n    \\"method\\": \\"tools/call\\",\n    \\"params\\": {\n      \\"name\\": \\"investigate\\",\n      \\"arguments\\": {\n        \\"resource_kind\\": \\"Deployment\\",\n        \\"resource_name\\": \\"api-server\\",\n        \\"namespace\\": \\"production\\",\n        \\"start_time\\": $(date -d \'1 hour ago\' +%s),\n        \\"end_time\\": $(date +%s),\n        \\"investigation_type\\": \\"incident\\"\n      }\n    },\n    \\"id\\": 2\n  }"\n'})}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Response"})," includes timeline with image update and failure events."]}),"\n",(0,r.jsx)(n.h2,{id:"example-2-post-mortem-analysis-complete-workflow",children:"Example 2: Post-Mortem Analysis (Complete Workflow)"}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Scenario"}),": Yesterday there was a 15-minute outage. You need a comprehensive post-mortem report."]}),"\n",(0,r.jsx)(n.h3,{id:"via-claude-desktop-1",children:"Via Claude Desktop"}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"You"}),":"]}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{children:"Run a post-mortem analysis for the incident yesterday from 14:00 to 14:30 UTC\nin the production namespace\n"})}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Claude"})," (Using ",(0,r.jsx)(n.code,{children:"post_mortem_incident_analysis"})," prompt):"]}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{children:'[Executing post-mortem analysis prompt with:\n  start_time: 2024-12-11 14:00 UTC\n  end_time: 2024-12-11 14:30 UTC\n  namespace: production]\n\n## Incident Post-Mortem Report\n\n### Incident Summary\n\nService outage in production namespace caused by ConfigMap deletion,\naffecting api-server deployment for 15 minutes. Service was restored\nafter ConfigMap was manually recreated from backup.\n\n### Timeline\n\n[14:00:05] **ConfigMap/production/api-config** - Deleted\n           Impact Score: 0.75 (high)\n\n[14:02:18] **Deployment/production/api-server** - Triggered rolling update\n           (ConfigMap referenced in pod spec)\n\n[14:02:45] **Pod/production/api-server-7d9f8c5b-x7k2p** - Status: Running \u2192 Error\n           Event: "Error: ConfigMap api-config not found"\n\n[14:02:52] **Pod/production/api-server-7d9f8c5b-z9k3p** - Status: Running \u2192 Error\n           (Same error)\n\n[14:03:00] **Service/production/api-server** - No ready endpoints\n           All pods unhealthy\n\n[14:15:30] **ConfigMap/production/api-config** - Created (restored from backup)\n\n[14:15:55] **Pod/production/api-server-9c8f7b6d-a3m5n** - Status: Running\n           (New pod started successfully)\n\n[14:16:10] **Service/production/api-server** - Endpoints restored\n           Service traffic resumed\n\n### Root Cause Analysis\n\n**Primary Cause**:\nConfigMap "api-config" was deleted, causing all pods referencing it to fail\nduring the subsequent rolling update.\n\n**Contributing Factors**:\n1. No version control or backup system for ConfigMaps\n2. Deployment configuration requires ConfigMap, but has no failure handling\n3. No RBAC restrictions preventing ConfigMap deletion\n4. No monitoring alerts on ConfigMap changes\n5. Manual restoration took 15 minutes (no documented procedure)\n\n**Evidence**:\n- resource_changes tool: ConfigMap deletion at 14:00:05 (impact_score: 0.75)\n- investigate tool: Pods transitioned Running \u2192 Error at 14:02:45\n- Kubernetes events: "ConfigMap api-config not found" (count: 24)\n\n### Impact Assessment\n\n**Service Impact**:\n- Total downtime: 15 minutes 55 seconds\n- Affected services: api-server (100% unavailable)\n- Error rate: 100% during outage\n\n**Resources Affected**:\n- 1 ConfigMap (deleted)\n- 1 Deployment (failed rollout)\n- 3 Pods (failed to start)\n- 1 Service (no endpoints)\n\n**User Impact**:\n- API requests returned 503 errors\n- Estimated affected users: ~500 (based on typical traffic)\n\n### Recommendations\n\n**Immediate Actions**:\n1. \u2705 Restore ConfigMap from backup (completed)\n2. \u2705 Verify all pods are healthy (completed)\n3. \u23f3 Document ConfigMap restoration procedure\n\n**Short-Term (This Week)**:\n1. Implement GitOps for ConfigMap management (FluxCD/ArgoCD)\n2. Add RBAC policy restricting ConfigMap deletions in production\n3. Set up alerts for ConfigMap changes (via Prometheus or kube-state-metrics)\n4. Add readiness probes with longer failure thresholds\n\n**Long-Term (This Quarter)**:\n1. Implement automated ConfigMap backup system\n2. Add application fallback to default configuration values\n3. Create runbook for ConfigMap-related incidents\n4. Review all deployments for critical ConfigMap dependencies\n\n### Data Gaps & Follow-Up Investigation\n\nTo complete the analysis, the following information is needed:\n\n1. **Who deleted the ConfigMap?**\n'})}),"\n",(0,r.jsxs)(n.p,{children:["kubectl logs -n kube-system -l component=kube-apiserver ",(0,r.jsx)(n.br,{}),"\n",'| grep "ConfigMap.*api-config.*delete"']}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{children:"\n2. **Application error logs**:\n"})}),"\n",(0,r.jsx)(n.p,{children:"kubectl logs -n production api-server-7d9f8c5b-x7k2p --previous"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{children:"\n3. **Monitoring data**:\n- Check Prometheus for request rate drop at 14:03\n- Review alerting timeline (did alerts fire?)\n- External monitoring (Datadog, New Relic) for user impact\n\n4. **Related changes**:\n"})}),"\n",(0,r.jsxs)(n.p,{children:['git log --since="2024-12-11 13:00" --until="2024-12-11 14:00" ',(0,r.jsx)(n.br,{}),"\n","-- k8s/production/configmaps/"]}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{children:"\n### Lessons Learned\n\n**What Went Well**:\n- Incident was detected within 3 minutes\n- ConfigMap backup was available\n- Team restored service within 16 minutes\n\n**What Went Wrong**:\n- No prevention mechanisms for accidental deletion\n- No automated recovery process\n- Lack of graceful degradation in application\n\n**Action Items**:\n- [ ] @ops-team: Implement GitOps for ConfigMaps (by Dec 18)\n- [ ] @ops-team: Add RBAC restrictions (by Dec 15)\n- [ ] @dev-team: Add ConfigMap change alerts (by Dec 20)\n- [ ] @dev-team: Implement application fallback config (by Q1 2025)\n- [ ] @all: Review and update incident runbooks (by Dec 22)\n"})}),"\n",(0,r.jsx)(n.h3,{id:"via-http-api",children:"Via HTTP API"}),"\n",(0,r.jsxs)(n.p,{children:["Use the ",(0,r.jsx)(n.code,{children:"post_mortem_incident_analysis"})," prompt via HTTP:"]}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-bash",children:'# Convert timestamps\nSTART_TIME=$(date -u -d "2024-12-11 14:00:00" +%s)\nEND_TIME=$(date -u -d "2024-12-11 14:30:00" +%s)\n\ncurl -X POST http://localhost:8081/mcp/v1 \\\n  -H "Content-Type: application/json" \\\n  -d "{\n    \\"jsonrpc\\": \\"2.0\\",\n    \\"method\\": \\"prompts/get\\",\n    \\"params\\": {\n      \\"name\\": \\"post_mortem_incident_analysis\\",\n      \\"arguments\\": {\n        \\"start_time\\": $START_TIME,\n        \\"end_time\\": $END_TIME,\n        \\"namespace\\": \\"production\\",\n        \\"incident_description\\": \\"API service outage\\"\n      }\n    },\n    \\"id\\": 3\n  }"\n'})}),"\n",(0,r.jsx)(n.p,{children:"Response includes the prompt that instructs the LLM to execute the 9-step post-mortem workflow."}),"\n",(0,r.jsx)(n.h2,{id:"example-3-live-incident-handling",children:"Example 3: Live Incident Handling"}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Scenario"}),": Pods are failing RIGHT NOW. You need immediate guidance."]}),"\n",(0,r.jsx)(n.h3,{id:"via-claude-desktop-2",children:"Via Claude Desktop"}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"You"}),":"]}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{children:"Pods in production namespace are failing right now. Help me troubleshoot!\n"})}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Claude"})," (Using ",(0,r.jsx)(n.code,{children:"live_incident_handling"})," prompt):"]}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{children:'[Executing live incident handling prompt with:\n  incident_start_time: now - 10 minutes (estimated)\n  namespace: production]\n\n## Live Incident Triage\n\n### Current Situation (as of 10:15:30)\n\nIncident started approximately 10 minutes ago (10:05).\n\n**Critical Issues**:\n- 5 Pods in Error state (all api-server pods)\n- Deployment "api-server" in Warning state\n- Service "api-server" has 0/5 ready endpoints\n\n### Recent Changes (Last 15 Minutes)\n\n[Calling resource_changes tool]\n\nHigh-impact changes detected:\n\n1. **[10:04:12] Deployment/production/api-server**\n   - Image updated: v1.2.0 \u2192 v1.3.0\n   - Impact Score: 0.80 (very high)\n   - Status transitions: Ready \u2192 Warning\n\n2. **[10:04:05] ConfigMap/production/api-config**\n   - ConfigMap updated (3 fields changed)\n   - Impact Score: 0.45 (medium)\n\n### Timeline of Failures\n\n[Calling investigate tool for Deployment/api-server]\n\n[10:04:12] Deployment updated (image + ConfigMap reference)\n[10:04:45] First pod failed to start\n           Event: "Error: environment variable DATABASE_URL not set"\n[10:05:10] All pods failing\n           Status: CrashLoopBackOff (restart count: 8)\n\n### Root Cause (Likely)\n\nThe deployment update introduced a new image (v1.3.0) that requires\nenvironment variable DATABASE_URL, but this variable is not defined\nin the updated ConfigMap.\n\n**Evidence**:\n- Pod events show "environment variable DATABASE_URL not set"\n- ConfigMap was updated 7 seconds before deployment\n- New image version likely added new required config\n\n### Immediate Mitigation Steps\n\n**Option 1: Rollback Deployment (Fastest - 30-60 seconds)**\n```bash\nkubectl rollout undo deployment/api-server -n production\n'})}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Option 2: Fix ConfigMap (If rollback not preferred)"})}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-bash",children:'# Add missing variable to ConfigMap\nkubectl edit configmap api-config -n production\n# Add: DATABASE_URL: "postgresql://..."\n\n# Restart deployment to pick up new config\nkubectl rollout restart deployment/api-server -n production\n'})}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Option 3: Emergency Patch"})}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-bash",children:'# Add env var directly to deployment\nkubectl set env deployment/api-server -n production \\\n  DATABASE_URL="postgresql://postgres:5432/api"\n'})}),"\n",(0,r.jsx)(n.h3,{id:"recommended-action",children:"Recommended Action"}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"ROLLBACK NOW"})," (Option 1) for fastest recovery, then fix the configuration\nissue before re-deploying v1.3.0."]}),"\n",(0,r.jsx)(n.h3,{id:"monitoring-for-recovery",children:"Monitoring for Recovery"}),"\n",(0,r.jsx)(n.p,{children:"After executing rollback:"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-bash",children:"# Watch pod status (should become Running in 30-60 sec)\nkubectl get pods -n production -l app=api-server -w\n\n# Verify service endpoints restored\nkubectl get endpoints api-server -n production\n\n# Check for new errors\nkubectl get events -n production --sort-by='.lastTimestamp' | head -20\n"})}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Expected Recovery Time"}),": 30-60 seconds after rollback"]}),"\n",(0,r.jsx)(n.h3,{id:"follow-up-actions-after-recovery",children:"Follow-Up Actions (After Recovery)"}),"\n",(0,r.jsxs)(n.ol,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:"Verify rollback succeeded:"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{children:"kubectl rollout status deployment/api-server -n production\n"})}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:"Check why v1.3.0 requires DATABASE_URL:"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{children:"# Review image changelog or contact dev team\n"})}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:"Update ConfigMap with missing variable"}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:"Test v1.3.0 in staging environment before re-deploying"}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:'Run full post-mortem analysis:\n"Run post_mortem_incident_analysis from 10:00 to 10:20"'}),"\n"]}),"\n"]}),"\n",(0,r.jsx)(n.h3,{id:"additional-investigation-needed",children:"Additional Investigation Needed"}),"\n",(0,r.jsx)(n.p,{children:"If rollback doesn't resolve the issue:"}),"\n",(0,r.jsxs)(n.ol,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:"Check container logs:"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{children:"kubectl logs api-server-85f6c9b8-k4x2p -n production --previous\n"})}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:"Verify image exists and is accessible:"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{children:"kubectl describe pod <pod-name> -n production | grep -A5 Events\n"})}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:"Check for resource constraints:"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{children:"kubectl top pods -n production\nkubectl describe nodes\n"})}),"\n"]}),"\n"]}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{children:"\n## Example 4: Resource Change Correlation\n\n**Scenario**: You notice degraded performance. You want to see what changed in the last 30 minutes.\n\n### Via Claude Desktop\n\n**You**:\n"})}),"\n",(0,r.jsx)(n.p,{children:"Show me all high-impact changes in the production namespace\nfrom 30 minutes ago to now"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{children:"\n**Claude**:\n"})}),"\n",(0,r.jsx)(n.p,{children:"[Calling resource_changes tool]"}),"\n",(0,r.jsx)(n.p,{children:"High-impact changes in production (last 30 minutes):"}),"\n",(0,r.jsx)(n.h3,{id:"changes-with-impact-score--05",children:"Changes with Impact Score > 0.5"}),"\n",(0,r.jsxs)(n.ol,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Deployment/production/api-server"})," (Impact: 0.80)"]}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Changed at: 10:04:12"}),"\n",(0,r.jsx)(n.li,{children:"Image: v1.2.0 \u2192 v1.3.0"}),"\n",(0,r.jsx)(n.li,{children:"Status transitions: Ready \u2192 Warning \u2192 Ready"}),"\n",(0,r.jsx)(n.li,{children:"Error events: 15"}),"\n",(0,r.jsx)(n.li,{children:"Rollback performed at 10:08:30"}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"ConfigMap/production/api-config"})," (Impact: 0.65)"]}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Changed at: 10:04:05"}),"\n",(0,r.jsx)(n.li,{children:"3 fields modified"}),"\n",(0,r.jsx)(n.li,{children:"Associated with deployment failure above"}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"HPA/production/api-server-hpa"})," (Impact: 0.55)"]}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Changed at: 10:15:00"}),"\n",(0,r.jsx)(n.li,{children:"Scaled: 3 \u2192 5 replicas (due to increased load during incident)"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsx)(n.h3,{id:"changes-with-impact-score-03-05",children:"Changes with Impact Score 0.3-0.5"}),"\n",(0,r.jsxs)(n.ol,{start:"4",children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Service/production/api-server"})," (Impact: 0.40)"]}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Warning events: 5"}),"\n",(0,r.jsx)(n.li,{children:"Endpoints removed/restored (correlated with pod failures)"}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Pod/production/cache-redis-0"})," (Impact: 0.35)"]}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Warning at: 10:12:15"}),"\n",(0,r.jsx)(n.li,{children:"High restart count (3 restarts)"}),"\n",(0,r.jsx)(n.li,{children:'Event: "Liveness probe failed"'}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsx)(n.h3,{id:"correlation-analysis",children:"Correlation Analysis"}),"\n",(0,r.jsx)(n.p,{children:"The timeline suggests:"}),"\n",(0,r.jsxs)(n.ol,{children:["\n",(0,r.jsx)(n.li,{children:"ConfigMap updated (10:04:05)"}),"\n",(0,r.jsx)(n.li,{children:"Deployment updated shortly after (10:04:12)"}),"\n",(0,r.jsx)(n.li,{children:"Pods failed due to missing configuration (10:04:45)"}),"\n",(0,r.jsx)(n.li,{children:"Service unavailable (10:05:00)"}),"\n",(0,r.jsx)(n.li,{children:"Rollback performed (10:08:30)"}),"\n",(0,r.jsx)(n.li,{children:"HPA scaled up (10:15:00) to handle recovery traffic"}),"\n"]}),"\n",(0,r.jsx)(n.p,{children:"The redis pod restarts (10:12:15) may be a side effect of the increased\nload during the incident, or a separate issue. Would you like me to\ninvestigate the redis pod?"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{children:"\n## Example 5: Multi-Namespace Investigation\n\n**Scenario**: You suspect an issue is affecting multiple namespaces.\n\n### Via Claude Desktop\n\n**You**:\n"})}),"\n",(0,r.jsx)(n.p,{children:"Check cluster health across all namespaces and identify any problems"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{children:"\n**Claude**:\n"})}),"\n",(0,r.jsx)(n.p,{children:"[Calling cluster_health without namespace filter]"}),"\n",(0,r.jsx)(n.p,{children:"Cluster-Wide Health Status: Warning"}),"\n",(0,r.jsx)(n.h3,{id:"overall-summary",children:"Overall Summary"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Total resources tracked: 247"}),"\n",(0,r.jsx)(n.li,{children:"Healthy: 228 (92%)"}),"\n",(0,r.jsx)(n.li,{children:"Warning: 14 (6%)"}),"\n",(0,r.jsx)(n.li,{children:"Error: 5 (2%)"}),"\n"]}),"\n",(0,r.jsx)(n.h3,{id:"issues-by-namespace",children:"Issues by Namespace"}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"production"})," (3 errors, 2 warnings):"]}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Pods: 3 in Error (api-server deployment)"}),"\n",(0,r.jsx)(n.li,{children:"Deployments: 1 in Warning"}),"\n"]}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"staging"})," (2 errors, 5 warnings):"]}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Pods: 2 in Error (database-migration job)"}),"\n",(0,r.jsx)(n.li,{children:"Jobs: 1 Failed"}),"\n"]}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"monitoring"})," (0 errors, 4 warnings):"]}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Pods: 4 in Warning (prometheus-server high memory)"}),"\n"]}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"kube-system"})," (0 errors, 3 warnings):"]}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Pods: 3 in Warning (coredns high restart count)"}),"\n"]}),"\n",(0,r.jsx)(n.h3,{id:"top-priority-issues",children:"Top Priority Issues"}),"\n",(0,r.jsxs)(n.ol,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"production/api-server"})," - CrashLoopBackOff (3 pods)\n\u2192 Needs immediate attention"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"staging/database-migration"})," - Job failed (2 pods)\n\u2192 Check migration logs"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"monitoring/prometheus-server"})," - High memory usage\n\u2192 May affect monitoring reliability"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"kube-system/coredns"})," - High restart count\n\u2192 Potential DNS issues"]}),"\n"]}),"\n"]}),"\n",(0,r.jsx)(n.p,{children:"Would you like me to investigate any of these in detail?"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{children:"\n**You**:\n"})}),"\n",(0,r.jsx)(n.p,{children:"Yes, investigate the coredns issue. It might be causing problems across namespaces."}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{children:"\n**Claude**:\n"})}),"\n",(0,r.jsx)(n.p,{children:"[Calling investigate tool for coredns pods]"}),"\n",(0,r.jsx)(n.p,{children:"CoreDNS Investigation:"}),"\n",(0,r.jsx)(n.p,{children:"Timeline (last hour):"}),"\n",(0,r.jsx)(n.p,{children:'[09:30] coredns-7d8b5f9c6b-x7k2p - Restart count: 0 \u2192 3\nEvents: "Liveness probe failed" (3 times)'}),"\n",(0,r.jsx)(n.p,{children:'[09:45] coredns-7d8b5f9c6b-z9k3p - Restart count: 0 \u2192 2\nEvents: "Liveness probe failed" (2 times)'}),"\n",(0,r.jsx)(n.p,{children:"Root Cause Indicators:"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"High restart count (5 total across 2 pods in 30 minutes)"}),"\n",(0,r.jsx)(n.li,{children:"All failures are liveness probe failures"}),"\n",(0,r.jsx)(n.li,{children:"Coincides with increased DNS query rate (per events)"}),"\n"]}),"\n",(0,r.jsx)(n.p,{children:"Investigation Prompts:"}),"\n",(0,r.jsxs)(n.ol,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:"Why are the CoreDNS liveness probes failing?"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Check if DNS resolution is slow (timeout issues)"}),"\n",(0,r.jsx)(n.li,{children:"Review CoreDNS resource limits (CPU/memory constraints)"}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:"Is this affecting other services?"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"DNS failures would cause pod startup issues cluster-wide"}),"\n",(0,r.jsx)(n.li,{children:"May explain some of the errors in production/staging"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsx)(n.p,{children:"Recommended Actions:"}),"\n",(0,r.jsxs)(n.ol,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:"Check CoreDNS resource usage:\nkubectl top pods -n kube-system -l k8s-app=kube-dns"}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:"Review CoreDNS logs for errors:\nkubectl logs -n kube-system -l k8s-app=kube-dns --tail=100"}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:"Increase CoreDNS resource limits if needed:\nkubectl edit deployment coredns -n kube-system"}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:"Consider scaling CoreDNS replicas:\nkubectl scale deployment coredns -n kube-system --replicas=3"}),"\n"]}),"\n"]}),"\n",(0,r.jsx)(n.p,{children:"Note: DNS issues are cluster-wide and high priority!"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{children:"\n## Example 6: Custom Resource Investigation (Flux GitRepository)\n\n**Scenario**: Your Flux GitRepository resource is failing, and you don't know why.\n\n### Via Claude Desktop\n\n**You**:\n"})}),"\n",(0,r.jsx)(n.p,{children:"Investigate the GitRepository resource flux-system/main-repo that's been failing\nfor the last 2 hours"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{children:"\n**Claude**:\n"})}),"\n",(0,r.jsx)(n.p,{children:"[Calling investigate tool for GitRepository/flux-system/main-repo]"}),"\n",(0,r.jsx)(n.p,{children:"GitRepository Investigation: flux-system/main-repo"}),"\n",(0,r.jsx)(n.p,{children:"Timeline (last 2 hours):"}),"\n",(0,r.jsxs)(n.p,{children:["[08:15:00] Status: Ready\nRevision: main@sha1",":a3b4c5d6"]}),"\n",(0,r.jsx)(n.p,{children:'[08:45:30] Status: Ready \u2192 Error\nEvent: "Failed to checkout repository: authentication required"\nRevision: Failed to fetch'}),"\n",(0,r.jsx)(n.p,{children:'[09:00:15] Reconciliation attempts: 8 (all failed)\nEvent: "SSH key authentication failed"'}),"\n",(0,r.jsxs)(n.p,{children:['[09:15:45] Status: Still Error\nEvent: "Unable to clone: ',(0,r.jsx)(n.a,{href:"mailto:git@github.com",children:"git@github.com"}),":org",'/repo.git"']}),"\n",(0,r.jsx)(n.p,{children:"Root Cause Analysis:"}),"\n",(0,r.jsx)(n.p,{children:"The GitRepository resource is failing to authenticate with GitHub\nusing SSH keys. This started at 08:45:30 and has persisted for\n~1.5 hours."}),"\n",(0,r.jsx)(n.p,{children:"Investigation Prompts:"}),"\n",(0,r.jsxs)(n.ol,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:"Why did SSH authentication suddenly fail?"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Was the SSH key rotated or revoked?"}),"\n",(0,r.jsx)(n.li,{children:"Did the GitHub repository change permissions?"}),"\n",(0,r.jsx)(n.li,{children:"Is the Secret containing SSH keys still present?"}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:"Are other GitRepository resources affected?"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"This may indicate a cluster-wide credential issue"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsx)(n.p,{children:"Immediate Actions:"}),"\n",(0,r.jsxs)(n.ol,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:"Check if the Secret exists:\nkubectl get secret flux-system-ssh -n flux-system"}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:"Verify Secret has correct SSH key:\nkubectl get secret flux-system-ssh -n flux-system -o yaml | grep -A5 identity"}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:["Test Git access manually:\nkubectl run debug-git --rm -it --image=alpine/git -- ",(0,r.jsx)(n.br,{}),"\n","git ls-remote ",(0,r.jsx)(n.a,{href:"mailto:git@github.com",children:"git@github.com"}),":org","/repo.git"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:["If key is missing or expired, recreate Secret:\nflux create secret git flux-system-ssh ",(0,r.jsx)(n.br,{}),"\n","--url=ssh://git@github.com/org/repo.git ",(0,r.jsx)(n.br,{}),"\n","--private-key-file=/path/to/new/key"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:"Force reconciliation:\nflux reconcile source git main-repo"}),"\n"]}),"\n"]}),"\n",(0,r.jsx)(n.p,{children:"Expected Recovery: Immediate after Secret is fixed"}),"\n",(0,r.jsx)(n.p,{children:"Would you like me to check other GitRepository resources to see if this is\na widespread issue?"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{children:'\n## Integration Patterns\n\nCommon ways to integrate MCP tools into workflows:\n\n### Pattern 1: Alert \u2192 Investigation\n\n**Trigger**: Prometheus/Alertmanager alert fires\n\n**Workflow**:\n1. Alert notification includes namespace and resource\n2. Operator asks Claude: "Investigate <resource> in <namespace>"\n3. Claude uses `investigate` tool to provide timeline and RCA prompts\n4. Operator runs suggested kubectl commands\n5. Issue is resolved or escalated\n\n**Example**:\n'})}),"\n",(0,r.jsx)(n.p,{children:"[PagerDuty Alert: High Pod Restart Rate - production/api-server]"}),"\n",(0,r.jsx)(n.p,{children:"You: Investigate deployment api-server in production namespace"}),"\n",(0,r.jsx)(n.p,{children:"Claude: [investigate tool]\nTimeline shows image update 10 minutes ago...\n[Provides immediate mitigation steps]"}),"\n",(0,r.jsx)(n.p,{children:"You: [Runs rollback command from Claude's suggestion]"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{children:'\n### Pattern 2: Incident \u2192 Post-Mortem\n\n**Trigger**: Incident is resolved, need documentation\n\n**Workflow**:\n1. Incident resolution completed\n2. Operator asks Claude: "Run post_mortem_incident_analysis from <start> to <end>"\n3. Claude executes full post-mortem prompt workflow\n4. Claude generates structured report\n5. Report is saved to incident management system\n\n**Example**:\n'})}),"\n",(0,r.jsx)(n.p,{children:"[Incident resolved at 15:30]"}),"\n",(0,r.jsx)(n.p,{children:"You: Run post-mortem analysis from 14:00 to 15:30 in production"}),"\n",(0,r.jsx)(n.p,{children:"Claude: [post_mortem_incident_analysis prompt]\n[Generates full report with timeline, RCA, recommendations]"}),"\n",(0,r.jsx)(n.p,{children:"You: [Copies report to Jira/GitHub/Confluence]"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{children:'\n### Pattern 3: Maintenance Window Verification\n\n**Trigger**: After deploying changes\n\n**Workflow**:\n1. Deploy changes (deployment, configmap, etc.)\n2. Ask Claude: "Show me changes in the last 15 minutes"\n3. Claude uses `resource_changes` to identify what actually changed\n4. Verify expected changes occurred, no unexpected side effects\n\n**Example**:\n'})}),"\n",(0,r.jsx)(n.p,{children:"[Deployed v2.0 to production at 16:00]"}),"\n",(0,r.jsx)(n.p,{children:"You: Show high-impact changes in production in last 15 minutes"}),"\n",(0,r.jsx)(n.p,{children:"Claude: [resource_changes tool]\nDeployment api-server updated: v1.9 \u2192 v2.0\nConfigMap api-config updated (expected)\nHPA scaled 3 \u2192 5 replicas (expected due to new load)"}),"\n",(0,r.jsx)(n.p,{children:"No unexpected errors detected."}),"\n",(0,r.jsx)(n.p,{children:"You: Great, deployment looks clean!"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{children:'\n### Pattern 4: Proactive Health Check\n\n**Trigger**: Daily/weekly routine check\n\n**Workflow**:\n1. Operator asks Claude: "Check cluster health for the last 24 hours"\n2. Claude uses `cluster_health` to identify any warnings or errors\n3. Operator addresses issues proactively before they become incidents\n\n**Example**:\n'})}),"\n",(0,r.jsx)(n.p,{children:"[Monday morning routine]"}),"\n",(0,r.jsx)(n.p,{children:"You: Check cluster health across all namespaces for the last 24 hours"}),"\n",(0,r.jsx)(n.p,{children:"Claude: [cluster_health tool]\nOverall: Healthy"}),"\n",(0,r.jsx)(n.p,{children:"Minor issues detected:"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"staging/database: 1 pod in Warning (high memory usage)"}),"\n",(0,r.jsx)(n.li,{children:"monitoring/prometheus: 2 restarts (known issue, non-critical)"}),"\n"]}),"\n",(0,r.jsx)(n.p,{children:"No action required, but consider increasing database memory limits."}),"\n",(0,r.jsx)(n.p,{children:"You: Noted, will increase memory in next maintenance window."}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{children:"\n## Claude Desktop Conversation Tips\n\n### Be Specific with Time Windows\n\n**\u274c Vague**:\n"})}),"\n",(0,r.jsx)(n.p,{children:"Check for issues recently"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{children:"\n**\u2705 Specific**:\n"})}),"\n",(0,r.jsx)(n.p,{children:"Check cluster health in the production namespace for the last 30 minutes"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{children:"\n### Provide Context\n\n**\u274c Minimal**:\n"})}),"\n",(0,r.jsx)(n.p,{children:"Investigate pod api-server-x7k2p"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{children:"\n**\u2705 With Context**:\n"})}),"\n",(0,r.jsx)(n.p,{children:"Investigate pod api-server-x7k2p in production namespace.\nWe deployed a new version 15 minutes ago and it started failing."}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{children:"\n### Ask for Specific Tools\n\n**\u274c Unclear**:\n"})}),"\n",(0,r.jsx)(n.p,{children:"Tell me what happened"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{children:"\n**\u2705 Tool-specific**:\n"})}),"\n",(0,r.jsx)(n.p,{children:"Use resource_changes to show me what changed in production in the last hour"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{children:'\n### Follow Up with "Why" Questions\n\n**Good conversation flow**:\n'})}),"\n",(0,r.jsx)(n.p,{children:"You: Check production namespace health"}),"\n",(0,r.jsx)(n.p,{children:"Claude: [Shows 3 pods in error]"}),"\n",(0,r.jsx)(n.p,{children:"You: Why are those pods failing?"}),"\n",(0,r.jsx)(n.p,{children:"Claude: [Uses investigate tool]\nThey failed after a deployment update..."}),"\n",(0,r.jsx)(n.p,{children:"You: What was updated in the deployment?"}),"\n",(0,r.jsx)(n.p,{children:"Claude: [Shows configuration change details]"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{children:"\n## Troubleshooting Common Scenarios\n\n### Empty Results\n\n**Problem**: Tool returns no data or empty results\n\n**Cause**: Spectre may not have data for the requested time window\n\n**Solution**:\n"})}),"\n",(0,r.jsx)(n.p,{children:"You: I'm getting empty results. Does Spectre have data for the last hour?"}),"\n",(0,r.jsx)(n.p,{children:"Claude: [Adjusts time window]\nLet me check a longer time period...\n[Calls cluster_health with 24-hour window]"}),"\n",(0,r.jsx)(n.p,{children:"I found data from 6 hours ago, but nothing in the last hour.\nThis suggests Spectre may not be actively indexing events."}),"\n",(0,r.jsx)(n.p,{children:"Check if Spectre is running: kubectl get pods -n spectre-system"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{children:"\n### Incomplete Analysis\n\n**Problem**: Claude's analysis seems superficial\n\n**Cause**: Need to dig deeper with multiple tools\n\n**Solution**:\n"})}),"\n",(0,r.jsx)(n.p,{children:"You: That analysis seems incomplete. Can you investigate further?"}),"\n",(0,r.jsx)(n.p,{children:"Claude: You're right. Let me use additional tools...\n[Calls investigate tool for related resources]\n[Calls resource_changes to find correlated events]\n[Calls resource_explorer to find similar issues]"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{children:"\n### Claude Doesn't Use Tools\n\n**Problem**: Claude responds without calling MCP tools\n\n**Cause**: Question wasn't framed to trigger tool use\n\n**Solution**:\n"})}),"\n",(0,r.jsx)(n.p,{children:'\u274c Bad: "What might cause pods to fail?"\n(Claude gives generic answer without using tools)'}),"\n",(0,r.jsx)(n.p,{children:'\u2705 Good: "Use cluster_health to check if any pods are currently failing"\n(Claude calls tool)'}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{children:"\n## Best Practices from Examples\n\n### \u2705 Do\n\n- **Start broad, then narrow**: Use `cluster_health` first, then `investigate` specific resources\n- **Specify namespaces**: Faster queries when scoped to one namespace\n- **Use time windows**: \"Last 30 minutes\" is more efficient than \"last 7 days\"\n- **Follow Claude's suggestions**: Run kubectl commands Claude recommends\n- **Chain investigations**: Use results from one tool to inform the next query\n- **Save post-mortem reports**: Copy Claude's formatted reports to your docs\n- **Verify with kubectl**: Always confirm Claude's findings with live cluster state\n\n### \u274c Don't\n\n- **Don't expect Claude to execute commands**: Claude suggests kubectl commands, you must run them\n- **Don't ignore kubectl logs**: Spectre shows events, but container logs are still needed\n- **Don't query very old data**: Check Spectre retention period (default: 7 days)\n- **Don't rely solely on AI**: Use Claude as an assistant, not a replacement for expertise\n- **Don't skip follow-up**: Claude often says \"Would you like me to investigate X?\" - say yes!\n- **Don't ignore data gaps**: Claude will mention \"Additional investigation needed\" - follow up on those\n\n## Related Documentation\n\n- [Getting Started with MCP](./getting-started.md) - Deploy and verify MCP integration\n- [Claude Desktop Integration](./claude-integration.md) - Set up Claude Desktop\n- [Tools Reference](./tools-reference/cluster-health.md) - Detailed API docs for all tools\n- [Prompts Reference](./prompts-reference/post-mortem.md) - Workflow guides for prompts\n- [MCP Configuration](../configuration/mcp-configuration.md) - Production configuration and tuning\n\n\x3c!-- Source: Synthesized from tool and prompt documentation, README.md examples --\x3e\n"})})]})}function p(e={}){const{wrapper:n}={...(0,t.R)(),...e.components};return n?(0,r.jsx)(n,{...e,children:(0,r.jsx)(d,{...e})}):d(e)}},8453:(e,n,i)=>{i.d(n,{R:()=>o,x:()=>l});var s=i(6540);const r={},t=s.createContext(r);function o(e){const n=s.useContext(t);return s.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function l(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(r):e.components||r:o(e.components),s.createElement(t.Provider,{value:n},e.children)}}}]);