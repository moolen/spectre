---
phase: 13-mcp-tools-patterns
plan: 01
type: execute
wave: 1
depends_on: []
files_modified:
  - internal/integration/logzio/tools_patterns.go
  - internal/integration/logzio/logzio.go
autonomous: true

must_haves:
  truths:
    - "logzio_{name}_patterns returns log templates sorted by occurrence count"
    - "Pattern mining uses existing Drain algorithm from internal/logprocessing/"
    - "Patterns tool accepts same parameters as VictoriaLogs (namespace, severity, limit, time range)"
    - "Novelty detection compares current patterns to previous time window"
    - "Tool enforces max 50 templates limit"
  artifacts:
    - path: "internal/integration/logzio/tools_patterns.go"
      provides: "PatternsTool with Execute method, exact match to VictoriaLogs structure"
      min_lines: 200
    - path: "internal/integration/logzio/logzio.go"
      provides: "templateStore field and initialization in Start()"
      exports: ["LogzioIntegration.templateStore"]
  key_links:
    - from: "internal/integration/logzio/tools_patterns.go"
      to: "internal/logprocessing.TemplateStore"
      via: "PatternsTool.templateStore field"
      pattern: "templateStore \\*logprocessing\\.TemplateStore"
    - from: "internal/integration/logzio/tools_patterns.go"
      to: "Client.QueryLogs"
      via: "fetchLogsWithSampling calls ctx.Client.QueryLogs"
      pattern: "ctx\\.Client\\.QueryLogs"
    - from: "internal/integration/logzio/logzio.go"
      to: "tools_patterns.PatternsTool"
      via: "RegisterTools instantiates PatternsTool with templateStore"
      pattern: "&PatternsTool\\{.*templateStore: l\\.templateStore"
---

<objective>
Implement pattern mining MCP tool for Logz.io integration with VictoriaLogs parity. Tool reuses existing Drain algorithm infrastructure from `internal/logprocessing/` and matches VictoriaLogs patterns tool API exactly for consistent AI experience across backends.

Purpose: Complete Logz.io progressive disclosure (overview → logs → patterns) with novelty detection for anomaly discovery
Output: Working `logzio_{name}_patterns` tool registered and operational
</objective>

<execution_context>
@~/.claude/get-shit-done/workflows/execute-plan.md
@~/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP-v1.2.md
@.planning/STATE.md
@.planning/phases/13-mcp-tools-patterns/13-CONTEXT.md
@.planning/phases/13-mcp-tools-patterns/13-RESEARCH.md
@.planning/phases/12-mcp-tools-overview-logs/12-02-SUMMARY.md

# Reference implementation (blueprint for cloning)
@internal/integration/victorialogs/tools_patterns.go

# Infrastructure already available
@internal/logprocessing/store.go
@internal/logprocessing/drain.go

# Logzio integration to modify
@internal/integration/logzio/logzio.go
@internal/integration/logzio/client.go
@internal/integration/logzio/tools_overview.go
@internal/integration/logzio/severity.go
</context>

<tasks>

<task type="auto">
  <name>Create patterns tool with VictoriaLogs parity</name>
  <files>internal/integration/logzio/tools_patterns.go</files>
  <action>
Clone VictoriaLogs patterns tool structure to Logzio, adapting ONLY log fetching mechanism:

**1. Copy exact types from victorialogs/tools_patterns.go:**
- PatternsParams (TimeRangeParams embedded, namespace, severity, limit)
- PatternsResponse (time_range, namespace, templates, total_logs, novel_count)
- PatternTemplate (pattern, count, is_novel, sample_log, pods, containers)
- templateMetadata (internal struct for metadata collection)

**2. Copy PatternsTool structure:**
```go
type PatternsTool struct {
    ctx           ToolContext
    templateStore *logprocessing.TemplateStore
}
```

**3. Copy Execute method logic exactly:**
- Parse parameters with namespace required validation
- Default limit to 50
- Parse time range with parseTimeRange helper
- Fetch current window logs with sampling (targetSamples * 20, 500-5000 range)
- Mine templates with metadata (sample, pods, containers)
- Fetch previous window logs (same duration before current)
- Mine templates from previous (no metadata needed)
- Compare windows with templateStore.CompareTimeWindows
- Build response with novelty flags
- Limit to params.Limit

**4. ADAPT fetchLogsWithSampling for Logz.io:**
Instead of VictoriaLogs QueryParams:
```go
// Logz.io version - uses Elasticsearch API
query := QueryParams{
    TimeRange: timeRange,
    Namespace: namespace,
    Limit:     maxLogs,
}

// Apply severity filter using GetErrorPattern/GetWarningPattern
switch severity {
case "error", "errors":
    query.RegexMatch = GetErrorPattern()
case "warn", "warning", "warnings":
    query.RegexMatch = GetWarningPattern()
}

result, err := t.ctx.Client.QueryLogs(ctx, query)
return result.Logs, nil
```

**5. Copy helper methods exactly:**
- mineTemplatesWithMetadata (process logs, collect metadata)
- mineTemplates (process logs, no metadata)
- extractMessage (handles Message field or JSON fallback)
- setToSlice (converts set to sorted slice)

**CRITICAL PARITY REQUIREMENTS:**
- Same parameter names and JSON tags
- Same response field names and types
- Same default limit (50)
- Same sampling multiplier (targetSamples * 20)
- Same max logs cap (500 min, 5000 max)
- Same metadata collection (pods, containers)
- Same novelty detection logic
- Same error handling (previous window failure = all novel)

**DO NOT:**
- Change parameter names or add new parameters
- Change response field names or structure
- Change default values or limits
- Skip metadata collection
- Break from VictoriaLogs behavior

WHY: AI assistants learn one patterns tool API and apply across all backends
  </action>
  <verify>
```bash
# Compile check
go build ./internal/integration/logzio/

# Verify struct matches VictoriaLogs
diff <(grep -A5 "type PatternsParams struct" internal/integration/victorialogs/tools_patterns.go) \
     <(grep -A5 "type PatternsParams struct" internal/integration/logzio/tools_patterns.go)

# Verify severity patterns reused
grep -q "GetErrorPattern()" internal/integration/logzio/tools_patterns.go
grep -q "GetWarningPattern()" internal/integration/logzio/tools_patterns.go

# Verify templateStore used
grep -q "templateStore.Process" internal/integration/logzio/tools_patterns.go
grep -q "templateStore.ListTemplates" internal/integration/logzio/tools_patterns.go
grep -q "templateStore.CompareTimeWindows" internal/integration/logzio/tools_patterns.go
```
  </verify>
  <done>
- tools_patterns.go exists with PatternsTool.Execute method
- PatternsParams, PatternsResponse, PatternTemplate types match VictoriaLogs exactly
- fetchLogsWithSampling uses Logz.io QueryParams with GetErrorPattern/GetWarningPattern
- Default limit is 50, max logs range is 500-5000
- Metadata collection includes sample_log, pods, containers
- Novelty detection via CompareTimeWindows
  </done>
</task>

<task type="auto">
  <name>Wire patterns tool into integration and initialize templateStore</name>
  <files>internal/integration/logzio/logzio.go</files>
  <action>
Add pattern mining infrastructure to LogzioIntegration:

**1. Add templateStore field to LogzioIntegration struct:**
```go
type LogzioIntegration struct {
    name          string
    config        Config
    client        *Client
    logger        *logging.Logger
    registry      integration.ToolRegistry
    secretWatcher *victorialogs.SecretWatcher
    templateStore *logprocessing.TemplateStore  // ADD THIS
}
```

**2. Initialize templateStore in Start() method:**
After creating client, before returning:
```go
// Initialize template store for pattern mining
l.templateStore = logprocessing.NewTemplateStore(logprocessing.DefaultDrainConfig())
l.logger.Info("Template store initialized for pattern mining")
```

**3. Register patterns tool in RegisterTools():**
After registering overview and logs tools, add patterns tool:
```go
// Instantiate patterns tool
patternsTool := &PatternsTool{
    ctx:           toolCtx,
    templateStore: l.templateStore,  // Pass the store
}

// Register patterns tool
patternsName := fmt.Sprintf("logzio_%s_patterns", l.name)
patternsDesc := fmt.Sprintf("Get aggregated log patterns with novelty detection for Logz.io %s. Returns log templates with occurrence counts. Use after overview to understand error patterns.", l.name)
patternsSchema := map[string]interface{}{
    "type": "object",
    "properties": map[string]interface{}{
        "namespace": map[string]interface{}{
            "type":        "string",
            "description": "Kubernetes namespace to query (required)",
        },
        "severity": map[string]interface{}{
            "type":        "string",
            "description": "Optional: filter by severity level (error, warn). Only logs matching the severity pattern will be processed.",
            "enum":        []string{"error", "warn"},
        },
        "start_time": map[string]interface{}{
            "type":        "integer",
            "description": "Start timestamp (Unix seconds or milliseconds). Default: 1 hour ago",
        },
        "end_time": map[string]interface{}{
            "type":        "integer",
            "description": "End timestamp (Unix seconds or milliseconds). Default: now",
        },
        "limit": map[string]interface{}{
            "type":        "integer",
            "description": "Max templates to return (default 50)",
        },
    },
    "required": []string{"namespace"},
}

if err := registry.RegisterTool(patternsName, patternsDesc, patternsTool.Execute, patternsSchema); err != nil {
    return fmt.Errorf("failed to register patterns tool: %w", err)
}
l.logger.Info("Registered tool: %s", patternsName)
```

**4. Update tool count in final log message:**
Change "Successfully registered 2 MCP tools" to "Successfully registered 3 MCP tools"

**DO NOT:**
- Change existing overview or logs tool registration
- Modify tool schema to differ from VictoriaLogs
- Skip templateStore initialization in Start()
- Forget to pass templateStore to PatternsTool

WHY: Pattern mining requires initialized TemplateStore, tool registration follows established pattern
  </action>
  <verify>
```bash
# Compile check
go build ./internal/integration/logzio/

# Verify templateStore field exists
grep -q "templateStore \*logprocessing.TemplateStore" internal/integration/logzio/logzio.go

# Verify initialization in Start()
grep -q "NewTemplateStore" internal/integration/logzio/logzio.go

# Verify patterns tool registered
grep -q "logzio_%s_patterns" internal/integration/logzio/logzio.go
grep -q "patternsTool := &PatternsTool{" internal/integration/logzio/logzio.go

# Verify tool count updated
grep -q "3 MCP tools" internal/integration/logzio/logzio.go

# Run tests
go test ./internal/integration/logzio/... -v
```
  </verify>
  <done>
- LogzioIntegration has templateStore field
- Start() initializes templateStore with DefaultDrainConfig()
- RegisterTools instantiates PatternsTool with templateStore
- Patterns tool registered as logzio_{name}_patterns
- Tool schema matches VictoriaLogs patterns schema
- Final log message shows "3 MCP tools"
- All tests pass
  </done>
</task>

</tasks>

<verification>
**Functional verification:**
```bash
# Build succeeds
go build ./internal/integration/logzio/

# All tests pass
go test ./internal/integration/logzio/... -v

# Type parity check - params match VictoriaLogs
diff <(grep -A10 "type PatternsParams" internal/integration/victorialogs/tools_patterns.go) \
     <(grep -A10 "type PatternsParams" internal/integration/logzio/tools_patterns.go)

# Type parity check - response matches VictoriaLogs
diff <(grep -A10 "type PatternsResponse" internal/integration/victorialogs/tools_patterns.go) \
     <(grep -A10 "type PatternsResponse" internal/integration/logzio/tools_patterns.go)

# Verify shared infrastructure used
grep -q "logprocessing.TemplateStore" internal/integration/logzio/tools_patterns.go
grep -q "logprocessing.DefaultDrainConfig" internal/integration/logzio/logzio.go
```

**Requirement coverage:**
- TOOL-03: Pattern mining returns templates with counts - IMPLEMENTED
- Pattern storage namespace-scoped - INHERITED from logprocessing.TemplateStore
- Max 50 templates enforced - DEFAULT LIMIT in PatternsParams
- Novelty detection via time window comparison - IMPLEMENTED in Execute
- Reuses Drain algorithm - IMPORTS internal/logprocessing
</verification>

<success_criteria>
- [ ] tools_patterns.go created with PatternsTool struct and Execute method
- [ ] PatternsParams exactly matches VictoriaLogs (namespace, severity, limit, time range)
- [ ] PatternsResponse exactly matches VictoriaLogs (time_range, namespace, templates, total_logs, novel_count)
- [ ] PatternTemplate includes all fields (pattern, count, is_novel, sample_log, pods, containers)
- [ ] fetchLogsWithSampling uses Logz.io Client.QueryLogs with GetErrorPattern/GetWarningPattern
- [ ] Sampling multiplier is targetSamples * 20 with 500-5000 range
- [ ] Metadata collection includes sample log, pods, containers
- [ ] Novelty detection via templateStore.CompareTimeWindows
- [ ] Previous window failure handled gracefully (all patterns marked novel)
- [ ] LogzioIntegration has templateStore field
- [ ] Start() initializes templateStore with DefaultDrainConfig()
- [ ] RegisterTools instantiates PatternsTool with templateStore
- [ ] Patterns tool registered as logzio_{name}_patterns
- [ ] Tool schema matches VictoriaLogs (same parameters, same required fields)
- [ ] Final log message shows 3 tools registered
- [ ] All tests pass
- [ ] Code compiles without errors
</success_criteria>

<output>
After completion, create `.planning/phases/13-mcp-tools-patterns/13-01-SUMMARY.md`

Summary must capture:
- VictoriaLogs parity achieved (exact parameter and response match)
- Shared infrastructure (internal/logprocessing reused)
- Logz.io-specific adaptations (Elasticsearch query builder)
- Tool registration pattern (same as overview/logs)
- Performance characteristics (sampling strategy)
- Any deviations from VictoriaLogs (should be none except log fetching)
</output>
