---
phase: 22-historical-analysis
plan: 02
type: execute
wave: 2
depends_on: ["22-01"]
files_modified:
  - internal/integration/grafana/alert_analysis_service.go
  - internal/integration/grafana/alert_analysis_service_test.go
  - internal/integration/grafana/categorization.go
  - internal/integration/grafana/categorization_test.go
  - internal/integration/grafana/transitions.go
autonomous: true

must_haves:
  truths:
    - "AlertAnalysisService fetches state transitions from graph with temporal filtering"
    - "Service computes flappiness score for any alert with sufficient history"
    - "Service compares current behavior to 7-day baseline with deviation scoring"
    - "Multi-label categorization produces both onset and pattern categories"
    - "Cache stores results with 5-minute TTL to handle repeated queries"
  artifacts:
    - path: "internal/integration/grafana/alert_analysis_service.go"
      provides: "Main analysis service orchestration"
      exports: ["AlertAnalysisService", "AnalyzeAlert"]
      min_lines: 150
    - path: "internal/integration/grafana/categorization.go"
      provides: "Multi-label alert categorization"
      exports: ["CategorizeAlert", "AlertCategories"]
      min_lines: 100
    - path: "internal/integration/grafana/transitions.go"
      provides: "Transition fetching with LOCF interpolation"
      exports: ["FetchStateTransitions"]
      min_lines: 80
  key_links:
    - from: "internal/integration/grafana/alert_analysis_service.go"
      to: "internal/integration/grafana/flappiness.go"
      via: "ComputeFlappinessScore call"
      pattern: "ComputeFlappinessScore\\("
    - from: "internal/integration/grafana/alert_analysis_service.go"
      to: "internal/integration/grafana/baseline.go"
      via: "ComputeRollingBaseline call"
      pattern: "ComputeRollingBaseline\\("
    - from: "internal/integration/grafana/alert_analysis_service.go"
      to: "github.com/hashicorp/golang-lru/v2/expirable"
      via: "5-minute TTL cache"
      pattern: "expirable\\.NewLRU"
    - from: "internal/integration/grafana/transitions.go"
      to: "internal/graph.Client"
      via: "Cypher query for STATE_TRANSITION edges"
      pattern: "ExecuteQuery.*STATE_TRANSITION"
---

<objective>
Create AlertAnalysisService that orchestrates flappiness detection, baseline comparison, and multi-label categorization using cached graph queries.

Purpose: Provide high-level analysis API that Phase 23 MCP tools can use to enrich alert data with historical context (flapping status, deviation from baseline, alert category).

Output: Service with 5-minute TTL cache, multi-label categorization, and graceful partial data handling.
</objective>

<execution_context>
@~/.claude/get-shit-done/workflows/execute-plan.md
@~/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/22-historical-analysis/22-CONTEXT.md
@.planning/phases/22-historical-analysis/22-RESEARCH.md
@.planning/phases/21-alert-sync-pipeline/21-01-SUMMARY.md

# Plan 22-01 outputs
@internal/integration/grafana/flappiness.go
@internal/integration/grafana/baseline.go

# Existing service patterns
@internal/integration/grafana/anomaly_service.go
@internal/integration/grafana/baseline_cache.go
@internal/integration/grafana/graph_builder.go
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create state transition fetcher with LOCF interpolation</name>
  <files>internal/integration/grafana/transitions.go</files>
  <action>
Create transitions.go with FetchStateTransitions function that queries graph for STATE_TRANSITION edges.

**Function signature:**
```go
func FetchStateTransitions(
    ctx context.Context,
    graphClient graph.Client,
    alertUID string,
    integrationName string,
    startTime time.Time,
    endTime time.Time,
) ([]StateTransition, error)
```

**Cypher query pattern (from Phase 21-01):**
```cypher
MATCH (a:Alert {uid: $uid, integration: $integration})-[t:STATE_TRANSITION]->(a)
WHERE t.timestamp >= $startTime
  AND t.timestamp <= $endTime
  AND t.expires_at > $now
RETURN t.from_state AS from_state,
       t.to_state AS to_state,
       t.timestamp AS timestamp
ORDER BY t.timestamp ASC
```

**Key implementation details:**
- Convert Go time.Time to UTC before formatting as RFC3339 (Phase 21 pattern)
- Parse timestamp strings back to time.Time from Cypher results
- Sort results chronologically (ORDER BY in query ensures this)
- Return empty slice (not error) if no transitions found (valid for new alerts)
- Use MERGE pattern for integration field matching (Phase 21-01 decision)

**LOCF interpolation:** NOT needed in this function - transitions are returned as-is. LOCF logic will be applied in categorization.go when computing state durations.

**Error handling:**
- Return graph.Client errors as-is (don't wrap excessively)
- Log warning if timestamp parsing fails for individual rows, skip row
- Continue parsing remaining rows on per-row errors
  </action>
  <verify>
Unit test in alert_analysis_service_test.go:
```go
func TestFetchStateTransitions(t *testing.T) {
    // Mock graph client returning sample transitions
    // Verify Cypher query contains correct WHERE clauses
    // Verify timestamps converted to UTC
    // Verify results sorted chronologically
}
```

Run: `go test ./internal/integration/grafana/... -run TestFetchStateTransitions -v`
  </verify>
  <done>
FetchStateTransitions function exists, queries graph with temporal filtering, returns sorted transitions chronologically, handles empty results gracefully.
  </done>
</task>

<task type="auto">
  <name>Task 2: Create multi-label categorization with LOCF duration computation</name>
  <files>internal/integration/grafana/categorization.go, internal/integration/grafana/categorization_test.go</files>
  <action>
Create categorization.go with CategorizeAlert function implementing multi-label categorization.

**Types:**
```go
type AlertCategories struct {
    Onset   []string // "new", "recent", "persistent", "chronic"
    Pattern []string // "stable-firing", "stable-normal", "flapping", "trending-worse", "trending-better"
}
```

**Function signature:**
```go
func CategorizeAlert(
    transitions []StateTransition,
    currentTime time.Time,
    flappinessScore float64, // from Plan 22-01 function
) AlertCategories
```

**Onset categorization (time-based):**
- Find first firing state in transitions (scan chronologically)
- If never fired → onset = ["stable-normal"]
- If first firing time:
  - < 1h ago → "new"
  - < 24h ago → "recent"
  - < 7d ago → "persistent"
  - >= 7d ago AND >80% time firing → "chronic"

**Chronic threshold calculation:**
- Use LOCF to compute total time in firing state over full 7 days
- Chronic if: (firingDuration / 7days) > 0.8

**Pattern categorization (behavior-based):**
- If flappinessScore > 0.7 → "flapping"
- Else compute trend:
  - Compare last 1h state distribution to prior 6h
  - If firing % increased by >20% → "trending-worse"
  - If firing % decreased by >20% → "trending-better"
  - Else if current state is "firing" → "stable-firing"
  - Else → "stable-normal"

**LOCF interpolation for duration:**
```go
func computeStateDurations(transitions []StateTransition, totalWindow time.Duration) map[string]time.Duration {
    durations := make(map[string]time.Duration)
    for i := 0; i < len(transitions)-1; i++ {
        state := transitions[i].ToState
        duration := transitions[i+1].Timestamp.Sub(transitions[i].Timestamp)
        durations[state] += duration
    }
    // Last state: carry forward to end of window
    if len(transitions) > 0 {
        lastState := transitions[len(transitions)-1].ToState
        lastDuration := totalWindow - transitions[len(transitions)-1].Timestamp.Sub(transitions[0].Timestamp)
        durations[lastState] += lastDuration
    }
    return durations
}
```

**Unit tests (categorization_test.go):**
- TestCategorizeAlert_New (alert firing <1h)
- TestCategorizeAlert_Recent (alert firing <24h)
- TestCategorizeAlert_Persistent (alert firing <7d)
- TestCategorizeAlert_Chronic (alert firing >80% of 7d)
- TestCategorizeAlert_Flapping (flappinessScore > 0.7)
- TestCategorizeAlert_TrendingWorse (firing % increased)
- TestCategorizeAlert_StableFiring (no flapping, no trend, currently firing)
- TestCategorizeAlert_MultiLabel (chronic + flapping both apply)

**Edge cases:**
- Empty transitions → onset=["stable-normal"], pattern=["stable-normal"]
- Insufficient data for trend (<2h history) → skip trend categorization, use stable-* only
  </action>
  <verify>
Run: `go test ./internal/integration/grafana/... -run TestCategorize -v`

Verify multi-label output:
```go
// Chronic alert that also flaps should have both categories
categories := CategorizeAlert(transitions, now, 0.8)
assert.Contains(t, categories.Onset, "chronic")
assert.Contains(t, categories.Pattern, "flapping")
```
  </verify>
  <done>
CategorizeAlert function returns multi-label categories, onset categories use time-based thresholds with LOCF duration computation, pattern categories combine flappiness and trend analysis, chronic threshold computed correctly (>80% firing), tests cover all category combinations including multi-label cases.
  </done>
</task>

<task type="auto">
  <name>Task 3: Create AlertAnalysisService with cache integration</name>
  <files>internal/integration/grafana/alert_analysis_service.go, internal/integration/grafana/alert_analysis_service_test.go</files>
  <action>
Create alert_analysis_service.go following AnomalyService pattern.

**Service struct:**
```go
type AlertAnalysisService struct {
    graphClient     graph.Client
    integrationName string
    cache           *expirable.LRU[string, AnalysisResult] // 5-minute TTL
    logger          *logging.Logger
}

type AnalysisResult struct {
    FlappinessScore float64
    DeviationScore  float64          // how many σ from baseline
    Baseline        StateDistribution
    Categories      AlertCategories
    ComputedAt      time.Time
    DataAvailable   time.Duration    // how much history was available
}
```

**Constructor:**
```go
func NewAlertAnalysisService(
    graphClient graph.Client,
    integrationName string,
    logger *logging.Logger,
) *AlertAnalysisService {
    // Create cache with 1000 max entries, 5-minute TTL
    cache := expirable.NewLRU[string, AnalysisResult](1000, nil, 5*time.Minute)
    return &AlertAnalysisService{
        graphClient:     graphClient,
        integrationName: integrationName,
        cache:           cache,
        logger:          logger,
    }
}
```

**AnalyzeAlert method:**
```go
func (s *AlertAnalysisService) AnalyzeAlert(ctx context.Context, alertUID string) (*AnalysisResult, error) {
    // Check cache first
    if cached, ok := s.cache.Get(alertUID); ok {
        s.logger.Debug("Cache hit for alert analysis %s", alertUID)
        return &cached, nil
    }

    // Fetch 7-day history
    endTime := time.Now()
    startTime := endTime.Add(-7 * 24 * time.Hour)
    transitions, err := FetchStateTransitions(ctx, s.graphClient, alertUID, s.integrationName, startTime, endTime)
    if err != nil {
        return nil, fmt.Errorf("fetch transitions: %w", err)
    }

    // Check minimum data requirement (24h)
    if len(transitions) == 0 {
        return nil, ErrInsufficientData{Available: 0, Required: 24 * time.Hour}
    }
    dataAvailable := endTime.Sub(transitions[0].Timestamp)
    if dataAvailable < 24*time.Hour {
        return nil, ErrInsufficientData{Available: dataAvailable, Required: 24 * time.Hour}
    }

    // Compute flappiness (6-hour window)
    flappinessScore := ComputeFlappinessScore(transitions, 6*time.Hour, endTime)

    // Compute baseline (from Plan 22-01)
    baseline, stdDev, err := ComputeRollingBaseline(transitions, 7)
    if err != nil {
        return nil, fmt.Errorf("compute baseline: %w", err)
    }

    // Compute current state distribution (last 1 hour)
    recentTransitions := filterTransitions(transitions, endTime.Add(-1*time.Hour), endTime)
    currentDist := computeCurrentDistribution(recentTransitions, 1*time.Hour)

    // Compare to baseline
    deviationScore := CompareToBaseline(currentDist, baseline, stdDev)

    // Categorize alert
    categories := CategorizeAlert(transitions, endTime, flappinessScore)

    // Build result
    result := AnalysisResult{
        FlappinessScore: flappinessScore,
        DeviationScore:  deviationScore,
        Baseline:        baseline,
        Categories:      categories,
        ComputedAt:      endTime,
        DataAvailable:   dataAvailable,
    }

    // Cache result
    s.cache.Add(alertUID, result)

    return &result, nil
}
```

**Helper functions:**
- filterTransitions: filter by time range
- computeCurrentDistribution: compute state distribution for recent window (last 1h)

**Unit tests (alert_analysis_service_test.go):**
- TestAlertAnalysisService_AnalyzeAlert_Success (full 7-day history)
- TestAlertAnalysisService_AnalyzeAlert_PartialData (24h-7d history, should succeed)
- TestAlertAnalysisService_AnalyzeAlert_InsufficientData (<24h history, should error)
- TestAlertAnalysisService_AnalyzeAlert_CacheHit (second call uses cache)
- TestAlertAnalysisService_AnalyzeAlert_EmptyTransitions (new alert, no history)

**Mock graph client:**
- Use strings.Contains to detect FetchStateTransitions query ("STATE_TRANSITION")
- Return mock transitions with various scenarios (stable, flapping, trending)
  </action>
  <verify>
Run: `go test ./internal/integration/grafana/... -run TestAlertAnalysisService -v`

Verify cache behavior:
```go
// First call - cache miss
result1, _ := service.AnalyzeAlert(ctx, "alert-123")
// Second call - cache hit (within 5 minutes)
result2, _ := service.AnalyzeAlert(ctx, "alert-123")
assert.Equal(t, result1.ComputedAt, result2.ComputedAt) // Same cached result
```

Verify insufficient data error:
```go
// Alert with <24h history
_, err := service.AnalyzeAlert(ctx, "new-alert")
assert.ErrorAs(t, err, &ErrInsufficientData{})
```
  </verify>
  <done>
AlertAnalysisService exists with AnalyzeAlert method, cache stores results with 5-minute TTL using golang-lru/v2/expirable, service orchestrates FetchStateTransitions + ComputeFlappinessScore + ComputeRollingBaseline + CategorizeAlert, insufficient data handling returns structured error with available/required durations, unit tests cover cache hit/miss and partial data scenarios.
  </done>
</task>

</tasks>

<verification>
**Overall phase checks:**
- [ ] All functions exported from service files (AlertAnalysisService, AnalyzeAlert, CategorizeAlert)
- [ ] Cache integration working: second call returns cached result
- [ ] Error types defined: ErrInsufficientData with Available and Required fields
- [ ] Multi-label categorization produces independent onset and pattern categories
- [ ] LOCF interpolation fills gaps correctly in duration computation
- [ ] All unit tests pass: `go test ./internal/integration/grafana/... -v`
- [ ] No golangci-lint errors: `golangci-lint run internal/integration/grafana/`
</verification>

<success_criteria>
**Measurable completion:**
- [ ] AlertAnalysisService struct exists with graphClient, integrationName, cache, logger fields
- [ ] AnalyzeAlert method returns AnalysisResult with flappiness, deviation, baseline, categories
- [ ] Cache uses hashicorp/golang-lru/v2/expirable with 5-minute TTL
- [ ] FetchStateTransitions queries graph with temporal WHERE filtering
- [ ] CategorizeAlert returns AlertCategories with onset and pattern arrays
- [ ] LOCF interpolation computes state durations correctly
- [ ] ErrInsufficientData returned for <24h history with clear error message
- [ ] Unit tests achieve >80% coverage for service, categorization, transitions
- [ ] Multi-label test case: chronic alert that flaps has both categories
- [ ] Cache hit test: second AnalyzeAlert call within 5 minutes returns cached result
</success_criteria>

<output>
After completion, create `.planning/phases/22-historical-analysis/22-02-SUMMARY.md` documenting:
- Service architecture (orchestration flow)
- Cache performance characteristics (TTL, size limits)
- Multi-label categorization examples
- LOCF interpolation implementation
- Edge cases handled (empty transitions, partial data, new alerts)
</output>
