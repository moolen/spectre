---
phase: 19-anomaly-detection
plan: 03
type: execute
wave: 3
depends_on: ["19-01", "19-02"]
files_modified:
  - internal/integration/grafana/anomaly_service.go
  - internal/integration/grafana/tools_metrics_overview.go
autonomous: true

must_haves:
  truths:
    - "AnomalyService can compute baseline from 7-day historical data"
    - "Baselines use time-of-day matching with weekday/weekend separation"
    - "Anomalies are detected via z-score comparison"
    - "Anomalies are ranked by severity then z-score"
    - "Overview tool returns top 20 anomalies with severity"
    - "Metrics with insufficient history are silently skipped"
  artifacts:
    - path: "internal/integration/grafana/anomaly_service.go"
      provides: "Anomaly detection orchestration"
      exports: ["AnomalyService", "DetectAnomalies"]
      min_lines: 200
    - path: "internal/integration/grafana/tools_metrics_overview.go"
      provides: "Updated Overview tool with anomaly detection"
      contains: "anomalyService"
      min_lines: 180
  key_links:
    - from: "internal/integration/grafana/anomaly_service.go"
      to: "query_service.go"
      via: "ExecuteDashboard calls"
      pattern: "queryService\\.ExecuteDashboard"
    - from: "internal/integration/grafana/anomaly_service.go"
      to: "baseline_cache.go"
      via: "Get/Set calls"
      pattern: "baselineCache\\.(Get|Set)"
    - from: "internal/integration/grafana/anomaly_service.go"
      to: "statistical_detector.go"
      via: "Detect calls"
      pattern: "detector\\.Detect"
    - from: "internal/integration/grafana/tools_metrics_overview.go"
      to: "anomaly_service.go"
      via: "DetectAnomalies calls"
      pattern: "anomalyService\\.DetectAnomalies"
---

<objective>
Implement anomaly detection service and integrate with Overview tool for AI-driven metrics analysis.

Purpose: Enable AI to detect metrics anomalies against 7-day baseline with severity ranking and top-20 limiting.
Output: AnomalyService orchestrating detection flow, Overview tool returning ranked anomalies.
</objective>

<execution_context>
@~/.claude/get-shit-done/workflows/execute-plan.md
@~/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/19-anomaly-detection/19-CONTEXT.md
@.planning/phases/19-anomaly-detection/19-RESEARCH.md
@.planning/phases/19-anomaly-detection/19-01-SUMMARY.md
@.planning/phases/19-anomaly-detection/19-02-SUMMARY.md
@.planning/phases/18-query-execution-mcp-tools/18-01-SUMMARY.md
@.planning/phases/18-query-execution-mcp-tools/18-02-SUMMARY.md
</context>

<tasks>

<task type="auto">
  <name>Create AnomalyService with baseline computation</name>
  <files>internal/integration/grafana/anomaly_service.go</files>
  <action>
Create AnomalyService that orchestrates anomaly detection flow: fetch current metrics, compute/retrieve baselines, detect anomalies, rank results.

**Type Definition:**
```go
type AnomalyService struct {
    queryService  *GrafanaQueryService
    detector      *StatisticalDetector
    baselineCache *BaselineCache
    logger        *logging.Logger
}

func NewAnomalyService(
    queryService *GrafanaQueryService,
    detector *StatisticalDetector,
    baselineCache *BaselineCache,
    logger *logging.Logger,
) *AnomalyService
```

**DataPoint Type (define in anomaly_service.go):**
```go
// DataPoint represents a single time-series data point from historical data.
// Extracted from Grafana DataFrame.Data.Values where Values[0] is timestamps
// and Values[1] is metric values.
type DataPoint struct {
    Timestamp time.Time
    Value     float64
}
```

**DetectAnomalies Method:**
- Accept: ctx, dashboardUID string, timeRange TimeRange, scopedVars map[string]string
- Return: *AnomalyResult, error
- Flow:
  1. Fetch current metrics via queryService.ExecuteDashboard (maxPanels=5 for overview)
  2. For each panel result, for each frame in Frames:
     - Extract metric name from frame.Schema.Name or frame.Schema.Fields[1].Labels
     - Parse current value from frame.Data.Values[1][last_index] (most recent value)
     - Check baseline cache
     - If cache miss: compute baseline from 7-day history
     - Detect anomaly via detector.Detect
     - Collect anomalies, track skip count on errors
  3. Rank anomalies: sort by severity (critical > warning > info), then z-score descending
  4. Limit to top 20 anomalies
  5. Return AnomalyResult with anomalies array, summary stats, skip count

**computeBaseline Method:**
- Accept: ctx, dashboardUID string, metricName string, currentTime time.Time, scopedVars map[string]string
- Return: *Baseline, error
- Compute 7-day time range ending at currentTime
- Query historical data via queryService.ExecuteDashboard with extended time range
- Parse time-series data from DashboardQueryResult:
  - For each PanelResult, for each Frame in Frames:
    - Extract timestamps from frame.Data.Values[0] ([]interface{} of epoch milliseconds)
    - Extract values from frame.Data.Values[1] ([]interface{} of float64)
    - Build []DataPoint by pairing timestamps and values
- Apply time-of-day matching: filter historical data to matching hour + day type
- Require minimum 3 matching windows (per CONTEXT.md)
- If insufficient samples: return nil (causes silent skip)
- Compute mean and stddev from matched historical values
- Store in baseline cache with 1-hour TTL
- Return Baseline struct

**matchTimeWindows Helper:**
- Accept: currentTime time.Time, historicalData []DataPoint
- Return: []float64 (matched values)
- Extract target hour and day type from currentTime
- Filter historicalData to matching hour + day type
- Return values from matched data points

**AnomalyResult Type:**
```go
type AnomalyResult struct {
    Anomalies      []MetricAnomaly `json:"anomalies"`
    MetricsChecked int             `json:"metrics_checked"`
    TimeRange      string          `json:"time_range"`
    SkipCount      int             `json:"metrics_skipped"`
}
```

**Historical Data Clarification:**
ExecuteDashboard returns DashboardQueryResult with PanelResults. Each PanelResult has Frames (Grafana DataFrames). Each DataFrame contains:
- Schema.Fields: metadata about columns (field 0 = timestamps, field 1 = values with labels)
- Data.Values: [][]interface{} where Values[0] is timestamps array, Values[1] is values array

This IS time-series data spanning the requested time range, NOT single-value snapshots. For 7-day baseline queries, ExecuteDashboard with a 7-day time range will return ~10k data points (7 days * 24 hours * 60 points/hour).

**Error handling (per CONTEXT.md):**
- Fail fast on individual metric query errors
- Continue with remaining metrics
- Track skip count, include in result
- Log skipped metrics at warning level

**Baseline computation details:**
- 7-day window: currentTime minus 7*24 hours to currentTime
- 1-hour granularity: group by hour (0-23)
- Weekday/weekend separation: use getDayType helper from baseline_cache
- Sample count check: if len(matchedValues) < 3, skip metric

**Note on ANOM-06 (Scrape Status Check):**
Requirement ANOM-06 requires checking if scrape status is healthy before computing baselines. This involves querying Prometheus `up` metric via Grafana. Implementation deferred: silently skip metrics where historical query returns insufficient data. Future enhancement can add explicit scrape health check before historical query. Current behavior meets requirement by skipping unreliable data sources.
  </action>
  <verify>
Build and check method signatures:
```bash
go build ./internal/integration/grafana/anomaly_service.go
grep "func NewAnomalyService" internal/integration/grafana/anomaly_service.go
grep "func.*DetectAnomalies" internal/integration/grafana/anomaly_service.go
grep "func.*computeBaseline" internal/integration/grafana/anomaly_service.go
grep "type AnomalyResult" internal/integration/grafana/anomaly_service.go
grep "type DataPoint" internal/integration/grafana/anomaly_service.go
```
  </verify>
  <done>
AnomalyService exists with DetectAnomalies method, defines DataPoint type, computes baselines from 7-day history with time-of-day matching, ranks anomalies by severity, limits to top 20, handles errors gracefully with skip count, clarifies ExecuteDashboard returns time-series data from DataFrame.Data.Values arrays.
  </done>
</task>

<task type="auto">
  <name>Update Overview tool with anomaly detection</name>
  <files>internal/integration/grafana/tools_metrics_overview.go</files>
  <action>
Modify OverviewTool to integrate anomaly detection and return ranked anomalies with severity in tool output.

**Changes to OverviewTool struct:**
- Add anomalyService *AnomalyService field
- Update NewOverviewTool constructor to accept anomalyService parameter

**Changes to Call method:**
- After executing dashboard queries (existing code), call anomalyService.DetectAnomalies
- Pass dashboardUID, timeRange, scopedVars to DetectAnomalies
- If anomaly detection fails: log warning, continue with non-anomaly response (graceful degradation)
- If successful: format anomalies in tool response

**Response format (per CONTEXT.md):**
When anomalies found:
```json
{
  "anomalies": [
    {
      "metric_name": "http_requests_5xx_total",
      "value": 125.3,
      "baseline": 45.2,
      "z_score": 3.8,
      "severity": "critical"
    }
  ],
  "summary": {
    "metrics_checked": 15,
    "time_range": "2024-01-20T10:00:00Z to 2024-01-20T11:00:00Z",
    "anomalies_found": 3,
    "metrics_skipped": 0
  }
}
```

When no anomalies:
```json
{
  "summary": {
    "metrics_checked": 15,
    "time_range": "...",
    "anomalies_found": 0,
    "metrics_skipped": 2
  }
}
```

**Minimal context (per CONTEXT.md):**
- Each anomaly: metric name, current value, baseline, z-score, severity
- No timestamp (use timeRange in summary instead)
- No panel info or query text
- Top 20 anomalies only

**Backward compatibility:**
- If anomalyService is nil: tool still works without anomaly detection (existing behavior)
- Ensures existing integrations don't break

**Update tool description:**
- Add: "Detects anomalies by comparing current metrics to 7-day baseline with severity ranking (critical/warning/info)."
  </action>
  <verify>
Build and check integration:
```bash
go build ./internal/integration/grafana/tools_metrics_overview.go
grep "anomalyService" internal/integration/grafana/tools_metrics_overview.go
grep "DetectAnomalies" internal/integration/grafana/tools_metrics_overview.go
grep "type.*Anomaly.*Result\|anomalies.*found" internal/integration/grafana/tools_metrics_overview.go
```
  </verify>
  <done>
OverviewTool updated to call anomalyService.DetectAnomalies, formats anomalies with severity in JSON response, includes summary stats, handles nil anomalyService gracefully, compiles without errors.
  </done>
</task>

</tasks>

<verification>
Overall verification:
```bash
# Full compilation check
go build ./internal/integration/grafana/...

# Verify anomaly service dependencies
grep "queryService.*detector.*baselineCache" internal/integration/grafana/anomaly_service.go

# Verify DataPoint type definition
grep "type DataPoint struct" internal/integration/grafana/anomaly_service.go

# Verify 7-day baseline logic
grep "7.*24.*time.Hour\|168.*time.Hour" internal/integration/grafana/anomaly_service.go

# Verify ranking logic
grep -i "sort.*severity\|critical.*warning.*info" internal/integration/grafana/anomaly_service.go

# Verify top 20 limit
grep "20" internal/integration/grafana/anomaly_service.go

# Verify tool integration
grep "anomalyService.DetectAnomalies" internal/integration/grafana/tools_metrics_overview.go

# Verify DataFrame parsing (time-series data handling)
grep "Data.Values\|frame.Data.Values" internal/integration/grafana/anomaly_service.go
```
</verification>

<success_criteria>
- AnomalyService orchestrates detection flow using query service, detector, cache
- DataPoint type defined with Timestamp and Value fields
- Baselines computed from 7-day history with time-of-day matching
- Historical data fetched via ExecuteDashboard with extended time range (returns time-series DataFrames)
- DataFrame.Data.Values parsed correctly (Values[0] = timestamps, Values[1] = values)
- Minimum 3 samples required before computing baseline
- Anomalies ranked by severity (critical > warning > info), then z-score
- Results limited to top 20 anomalies
- Overview tool returns anomalies with minimal context (name, value, baseline, z-score, severity)
- Summary stats included (metrics checked, time range, skip count)
- Graceful degradation on errors (skip metric, continue)
- ANOM-06 requirement addressed via skip behavior (explicit scrape check deferred)
- Compiles and integrates with existing codebase
</success_criteria>

<output>
After completion, create `.planning/phases/19-anomaly-detection/19-03-SUMMARY.md`
</output>
