---
phase: 19-anomaly-detection
plan: 02
type: execute
wave: 2
depends_on: ["19-01"]
files_modified:
  - internal/integration/grafana/baseline_cache.go
autonomous: true

must_haves:
  truths:
    - "Cache hit avoids expensive historical queries (performance observable)"
    - "Expired baselines trigger recomputation automatically"
    - "Baseline cache operates transparently to caller (no awareness of caching)"
    - "Cache serves correct baseline per time-of-day and day-type context"
  artifacts:
    - path: "internal/integration/grafana/baseline_cache.go"
      provides: "Graph-backed baseline cache with TTL"
      exports: ["BaselineCache", "Get", "Set"]
      min_lines: 150
  key_links:
    - from: "internal/integration/grafana/baseline_cache.go"
      to: "graph.Client"
      via: "ExecuteQuery calls"
      pattern: "ExecuteQuery.*Cypher"
    - from: "internal/integration/grafana/baseline_cache.go"
      to: "baseline.go"
      via: "Baseline type usage"
      pattern: "\\*Baseline"
---

<objective>
Implement graph-backed baseline cache with TTL support using FalkorDB Cypher queries.

Purpose: Cache computed baselines for 1 hour to avoid expensive historical queries on every anomaly detection request.
Output: BaselineCache with Get/Set methods storing baselines in FalkorDB with expiration.
</objective>

<execution_context>
@~/.claude/get-shit-done/workflows/execute-plan.md
@~/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/19-anomaly-detection/19-CONTEXT.md
@.planning/phases/19-anomaly-detection/19-RESEARCH.md
@.planning/phases/19-anomaly-detection/19-01-SUMMARY.md
</context>

<tasks>

<task type="auto">
  <name>Create baseline cache with FalkorDB storage</name>
  <files>internal/integration/grafana/baseline_cache.go</files>
  <action>
Create BaselineCache type that stores computed baselines in FalkorDB graph with TTL.

**Type Definition:**
```go
type BaselineCache struct {
    graphClient graph.Client
    logger      *logging.Logger
}

func NewBaselineCache(graphClient graph.Client, logger *logging.Logger) *BaselineCache {
    return &BaselineCache{
        graphClient: graphClient,
        logger:      logger,
    }
}
```

**Get Method:**
- Accept: ctx, metricName string, t time.Time
- Return: *Baseline, error
- Extract hour (t.Hour()) and day type (weekday vs weekend)
- Use time.Weekday() to determine if Saturday/Sunday â†’ "weekend", else "weekday"
- Query FalkorDB for matching baseline node:
  ```cypher
  MATCH (b:Baseline {
      metric_name: $metric_name,
      window_hour: $hour,
      day_type: $day_type
  })
  WHERE b.expires_at > $now
  RETURN b.mean, b.stddev, b.sample_count
  ```
- Parse result into Baseline struct
- Return nil if no rows (cache miss)
- Log cache hit/miss at debug level

**Set Method:**
- Accept: ctx, baseline *Baseline, ttl time.Duration
- Return: error
- Compute expiration: time.Now().Add(ttl).Unix()
- Use MERGE to create or update baseline node:
  ```cypher
  MERGE (b:Baseline {
      metric_name: $metric_name,
      window_hour: $window_hour,
      day_type: $day_type
  })
  SET b.mean = $mean,
      b.stddev = $stddev,
      b.sample_count = $sample_count,
      b.expires_at = $expires_at
  ```
- Log cache write at debug level

**Helper Functions:**
- getDayType(t time.Time) string - returns "weekday" or "weekend"
- isWeekend(t time.Time) bool - checks if Saturday or Sunday

**Follow existing patterns:**
- Use graph.GraphQuery struct from existing codebase
- Parameters as map[string]interface{}
- Error wrapping with fmt.Errorf
- Logger with component prefix: logger.With("component", "baseline_cache")

**Graph integration:**
- Use the same graph client pattern as graph_builder.go
- Query execution via graphClient.ExecuteQuery(ctx, graph.GraphQuery{...})
- Result parsing from result.Rows (slice of row maps)

**TTL implementation (per RESEARCH.md):**
- Store expires_at as Unix timestamp (int64)
- Filter in WHERE clause, not application-side cleanup
- Graph database handles timestamp comparison efficiently
  </action>
  <verify>
Build the file and check method signatures exist:
```bash
go build ./internal/integration/grafana/baseline_cache.go
grep "func NewBaselineCache" internal/integration/grafana/baseline_cache.go
grep "func.*Get.*context.Context.*string.*time.Time" internal/integration/grafana/baseline_cache.go
grep "func.*Set.*context.Context.*Baseline.*time.Duration" internal/integration/grafana/baseline_cache.go
grep "getDayType" internal/integration/grafana/baseline_cache.go
```
  </verify>
  <done>
BaselineCache type exists with Get/Set methods, uses FalkorDB Cypher queries with TTL via expires_at timestamp, handles weekday/weekend separation, compiles without errors.
  </done>
</task>

</tasks>

<verification>
Overall verification:
```bash
# Compilation check
go build ./internal/integration/grafana/...

# Verify Baseline node structure in Cypher queries
grep "metric_name.*window_hour.*day_type" internal/integration/grafana/baseline_cache.go
grep "expires_at" internal/integration/grafana/baseline_cache.go

# Verify weekday/weekend handling
grep "isWeekend\|getDayType" internal/integration/grafana/baseline_cache.go
```
</verification>

<success_criteria>
- BaselineCache type created with graph client dependency
- Get method queries FalkorDB with TTL filtering
- Set method uses MERGE for upsert semantics
- Weekday/weekend separation implemented
- 1-hour granularity via window_hour field
- Compiles and integrates with existing graph.Client interface
</success_criteria>

<output>
After completion, create `.planning/phases/19-anomaly-detection/19-02-SUMMARY.md`
</output>
