---
phase: 03-victorialogs-client-pipeline
plan: 02
type: execute
wave: 2
depends_on: ["03-01"]
files_modified:
  - internal/integration/victorialogs/metrics.go
  - internal/integration/victorialogs/pipeline.go
autonomous: true

must_haves:
  truths:
    - "Pipeline accepts log entries via Ingest method"
    - "Pipeline batches entries into groups of 100 before sending"
    - "Pipeline blocks when buffer is full (backpressure handling)"
    - "Pipeline exposes Prometheus metrics for queue depth and throughput"
    - "Pipeline gracefully shuts down with timeout, flushing remaining entries"
  artifacts:
    - path: "internal/integration/victorialogs/metrics.go"
      provides: "Prometheus metrics for pipeline observability"
      exports: ["Metrics", "NewMetrics"]
    - path: "internal/integration/victorialogs/pipeline.go"
      provides: "Backpressure-aware batch processing pipeline"
      exports: ["Pipeline", "NewPipeline", "Start", "Stop", "Ingest"]
      min_lines: 150
  key_links:
    - from: "internal/integration/victorialogs/pipeline.go"
      to: "internal/integration/victorialogs/metrics.go"
      via: "Pipeline updates Prometheus metrics on ingest and batch send"
      pattern: "metrics\\.(QueueDepth|BatchesTotal|ErrorsTotal)"
    - from: "internal/integration/victorialogs/pipeline.go"
      to: "internal/integration/victorialogs/client.go"
      via: "Pipeline calls client.IngestBatch to send batched logs"
      pattern: "client\\.IngestBatch"
    - from: "internal/integration/victorialogs/pipeline.go"
      to: "bounded channel"
      via: "make(chan LogEntry, 1000) creates buffer with backpressure"
      pattern: "make\\(chan.*1000\\)"
---

<objective>
Implement backpressure-aware log ingestion pipeline with Prometheus metrics for production observability.

Purpose: Handle log ingestion with bounded memory usage via buffered channels (1000-item buffer), batch processing (100 logs per batch), and graceful shutdown. Expose pipeline health via Prometheus metrics (queue depth, throughput, errors).

Output: Production-ready pipeline with natural backpressure (blocking when full), periodic batch flushing, and clean shutdown with timeout.
</objective>

<execution_context>
@/home/moritz/.claude/get-shit-done/workflows/execute-plan.md
@/home/moritz/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@/home/moritz/dev/spectre-via-ssh/.planning/PROJECT.md
@/home/moritz/dev/spectre-via-ssh/.planning/ROADMAP.md
@/home/moritz/dev/spectre-via-ssh/.planning/STATE.md
@/home/moritz/dev/spectre-via-ssh/.planning/phases/03-victorialogs-client-pipeline/03-CONTEXT.md
@/home/moritz/dev/spectre-via-ssh/.planning/phases/03-victorialogs-client-pipeline/03-RESEARCH.md
@/home/moritz/dev/spectre-via-ssh/.planning/phases/03-victorialogs-client-pipeline/03-01-SUMMARY.md
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create Prometheus metrics</name>
  <files>
internal/integration/victorialogs/metrics.go
  </files>
  <action>
Create metrics.go with Prometheus instrumentation for pipeline observability:

Metrics struct:
- QueueDepth prometheus.Gauge (current number of logs in pipeline buffer)
- BatchesTotal prometheus.Counter (total number of logs sent to VictoriaLogs)
- ErrorsTotal prometheus.Counter (total number of pipeline errors)

NewMetrics(reg prometheus.Registerer, instanceName string) *Metrics:
- Create QueueDepth as prometheus.NewGauge with:
  - Name: "victorialogs_pipeline_queue_depth"
  - Help: "Current number of logs in pipeline buffer"
  - ConstLabels: {"instance": instanceName}
- Create BatchesTotal as prometheus.NewCounter with:
  - Name: "victorialogs_pipeline_logs_total"
  - Help: "Total number of logs sent to VictoriaLogs"
  - ConstLabels: {"instance": instanceName}
- Create ErrorsTotal as prometheus.NewCounter with:
  - Name: "victorialogs_pipeline_errors_total"
  - Help: "Total number of pipeline errors"
  - ConstLabels: {"instance": instanceName}
- Call reg.MustRegister for all three metrics
- Return &Metrics{QueueDepth, BatchesTotal, ErrorsTotal}

IMPORTANT:
- Use prometheus.Registerer interface (not concrete Registry) for testing flexibility
- ConstLabels with instance name allows multiple VictoriaLogs instances
- Counter for BatchesTotal tracks log count, not batch count (increment by len(batch))
  </action>
  <verify>
go build ./internal/integration/victorialogs/... succeeds
grep -r "prometheus.NewGauge\|prometheus.NewCounter" internal/integration/victorialogs/metrics.go confirms metric creation
  </verify>
  <done>
metrics.go exports Metrics struct and NewMetrics constructor
Three metrics defined: QueueDepth (gauge), BatchesTotal (counter), ErrorsTotal (counter)
Metrics use instance name as ConstLabel for multi-instance support
Code compiles without errors
  </done>
</task>

<task type="auto">
  <name>Task 2: Create backpressure pipeline</name>
  <files>
internal/integration/victorialogs/pipeline.go
  </files>
  <action>
Create pipeline.go with bounded channel pipeline for backpressure handling:

Pipeline struct:
- logChan chan LogEntry (buffer size: 1000)
- batchSize int (fixed: 100)
- client *Client (VictoriaLogs HTTP client)
- metrics *Metrics (Prometheus metrics)
- logger *logging.Logger
- wg sync.WaitGroup (worker coordination)
- ctx context.Context (cancellation)
- cancel context.CancelFunc

NewPipeline(client *Client, metrics *Metrics, instanceName string) *Pipeline:
- Create logger with component name "victorialogs.pipeline.{instanceName}"
- Return &Pipeline with client, metrics, batchSize=100, logger (logChan created in Start)

Start(ctx context.Context) error:
- Create cancellable context: p.ctx, p.cancel = context.WithCancel(ctx)
- Create bounded channel: p.logChan = make(chan LogEntry, 1000)
- Start batch processor worker: p.wg.Add(1), go p.batchProcessor()
- Log "Pipeline started with buffer=1000, batchSize=100"
- Return nil

Ingest(entry LogEntry) error:
- Use select with two cases:
  1. case p.logChan <- entry: update metrics.QueueDepth.Set(float64(len(p.logChan))), return nil
  2. case <-p.ctx.Done(): return fmt.Errorf("pipeline stopped")
- Note: Blocks when channel full (natural backpressure - no default case!)

batchProcessor() (private goroutine):
- defer p.wg.Done()
- Create batch slice: batch := make([]LogEntry, 0, p.batchSize)
- Create ticker: ticker := time.NewTicker(1 * time.Second), defer ticker.Stop()
- Loop with select on three cases:
  1. entry, ok := <-p.logChan:
     - if !ok (channel closed): flush remaining batch if len(batch) > 0, return
     - append entry to batch
     - update metrics.QueueDepth.Set(float64(len(p.logChan)))
     - if len(batch) >= p.batchSize: call p.sendBatch(batch), reset batch = batch[:0]
  2. <-ticker.C (1 second timeout):
     - if len(batch) > 0: call p.sendBatch(batch), reset batch = batch[:0]
  3. <-p.ctx.Done():
     - flush remaining batch if len(batch) > 0, return

sendBatch(batch []LogEntry) (private method):
- Call p.client.IngestBatch(p.ctx, batch)
- If err != nil: increment p.metrics.ErrorsTotal.Inc(), log error, return (don't crash)
- Increment p.metrics.BatchesTotal.Add(float64(len(batch))) (count logs, not batches!)
- Log debug: "Sent batch of {len} logs"

Stop(ctx context.Context) error:
- Log "Stopping pipeline, draining buffer..."
- Call p.cancel() to signal shutdown
- Close(p.logChan) to drain
- Create done channel: done := make(chan struct{})
- Start goroutine: wait for p.wg, close done
- Use select with two cases:
  1. <-done: log "Pipeline stopped cleanly", return nil
  2. <-ctx.Done(): log "Pipeline shutdown timeout", return fmt.Errorf("shutdown timeout")

CRITICAL PATTERNS:
- Bounded channel (1000) provides natural backpressure via blocking send
- No default case in Ingest select - MUST block when full (no data loss)
- Ticker ensures partial batches are flushed within 1 second
- Graceful shutdown: cancel → close channel → wait for worker with timeout
- sendBatch logs errors but doesn't crash (resilience)
- Update QueueDepth on every ingest and batch receive

NOTE: IngestBatch method will be added to Client in Task 2 - for now, add a placeholder:
- Add IngestBatch(ctx context.Context, entries []LogEntry) error method to client.go
- POST entries as JSON array to {baseURL}/insert/jsonline
- Same error handling pattern (read body to completion)
  </action>
  <verify>
go build ./internal/integration/victorialogs/... succeeds
grep -r "make(chan.*1000)" internal/integration/victorialogs/pipeline.go confirms bounded buffer
grep -r "case p.logChan <- entry" internal/integration/victorialogs/pipeline.go confirms blocking send (no default)
grep -r "metrics.QueueDepth.Set" internal/integration/victorialogs/pipeline.go confirms metric updates
  </verify>
  <done>
pipeline.go exports Pipeline struct with NewPipeline, Start, Stop, Ingest
Pipeline uses bounded channel (1000) with blocking semantics for backpressure
Batch processor accumulates 100 entries before sending, flushes on 1-second ticker
Metrics updated on ingest and batch send
Graceful shutdown with timeout handling
Code compiles without errors
  </done>
</task>

</tasks>

<verification>
After both tasks complete:
- All files compile: go build ./internal/integration/victorialogs/...
- Metrics defined with proper Prometheus types (Gauge, Counter)
- Pipeline uses bounded channel (grep confirms make(chan LogEntry, 1000))
- Ingest blocks when full (no default case in select)
- Batch processor flushes on size (100) or timeout (1 second)
</verification>

<success_criteria>
1. metrics.go defines three Prometheus metrics with proper types and labels
2. pipeline.go implements bounded channel with blocking backpressure
3. Pipeline batches 100 entries before sending to VictoriaLogs
4. Pipeline gracefully shuts down with timeout, flushing remaining entries
5. Metrics updated on every ingest and batch send
6. All code compiles without errors and follows project conventions
</success_criteria>

<output>
After completion, create `.planning/phases/03-victorialogs-client-pipeline/03-02-SUMMARY.md`
</output>
